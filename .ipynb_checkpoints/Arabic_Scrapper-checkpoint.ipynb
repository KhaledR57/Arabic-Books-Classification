{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import zip_longest\n",
    "import csv\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from textblob_ar import TextBlob\n",
    "from textblob_ar.correction import TextCorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "page switched\n",
      "5957\n"
     ]
    }
   ],
   "source": [
    "Author = []\n",
    "title = []\n",
    "links = []\n",
    "book = []\n",
    "language = []\n",
    "publishing_house = []\n",
    "size = []\n",
    "format = []\n",
    "category = []\n",
    "page_num = 1\n",
    "numbers = []\n",
    "no_of_pages = []\n",
    "page_n = []\n",
    "brief = []  # في رغيف\n",
    "\n",
    "main = \"https://www.arab-books.com/\"    # The Main Link Of The Website\n",
    "\n",
    "result_main = requests.get(main)        # Request The Link\n",
    "\n",
    "src = result_main.content               # Load Website Content (HTML - JS - ...)\n",
    "# print(src)\n",
    "\n",
    "# parse content\n",
    "soup = BeautifulSoup(src, 'lxml')       # Pass Website Content To Parsser\n",
    "# print(soup)\n",
    "\n",
    "page = soup.find_all(\"a\", {\"class\":\"page-numbers\"})  # Get All <a> Tags That Its Class Is \"page-numbers\"\n",
    "\n",
    "for i in page :\n",
    "    page_n.append(i.text)               # Get The Text from \"page-numbers\"\n",
    "\n",
    "web_pages = int(page_n[2])              # The Number Of Last Page\n",
    "\n",
    "#print(web_pages)\n",
    "\n",
    "##### auto correct\n",
    "def correct(word):\n",
    "    ret = \"\"\n",
    "    blob = TextBlob(word)               # Tokenize\n",
    "    print(blob.tokens)\n",
    "    for token in blob.tokens:           # Iterate over all tokens\n",
    "        ret += TextCorrection().correction(token, top=True) +\" \"    # Correct Misspelled Tokens Then Append it\n",
    "    return ret\n",
    "\n",
    "x = 5\n",
    "while page_num <= web_pages:           # Iterate over all Web Pages\n",
    "#     if x == 0:\n",
    "#         break\n",
    "#     x-=1\n",
    "    # target URL\n",
    "    url = f\"https://www.arab-books.com//page/{page_num}\"    # Update URL to go to next page\n",
    "\n",
    "    result = requests.get(url)\n",
    "\n",
    "    src = result.content\n",
    "    #print(src)\n",
    "\n",
    "\n",
    "    # parse content\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    #print(soup)\n",
    "\n",
    "\n",
    "    Authors = soup.find_all(\"div\", {\"class\":\"book-writer\"})\n",
    "    #print(Authors)\n",
    "\n",
    "    titles = soup.find_all(\"div\", {\"class\":\"excerpt-book\"})\n",
    "    #print(titles)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(Authors)):\n",
    "        if Authors[i].text.replace(\"\\n\", \"\") == 'الكاتب هارون يحيىالكاتب هارون يحيى':\n",
    "            Author.append(\"هارون يحيى\")\n",
    "        else:\n",
    "            Author.append(Authors[i].text)\n",
    "        title.append(titles[i].text)\n",
    "        links.append(titles[i].find(\"a\").attrs[\"href\"])\n",
    "\n",
    "    # Correct And Remove \n",
    "    Author = [s.replace(\"\\n\", \"\") for s in Author]\n",
    "    Author = [s.replace(\"الكاتب \", \"\") for s in Author]\n",
    "    Author = [correct(s) for s in Author]       # Correct\n",
    "    title = [s.replace(\"PDF\", \"\") for s in title]\n",
    "    title = [s.replace(\"\\n\", \"\") for s in title]\n",
    "    title = [correct(s) for s in title]         # Correct\n",
    "    \n",
    "    \n",
    "    #print(links)\n",
    "    #print(Author)\n",
    "    #print(title)\n",
    "\n",
    "    page_num +=1\n",
    "    if page_num == 111 :       # Contain Broken Link\n",
    "        page_num = page_num + 1\n",
    "\n",
    "    print(\"page switched\")\n",
    "\n",
    "\n",
    "for link in links:            # Iterate over all Links of The Books\n",
    "    book = {}\n",
    "    result = requests.get(link)\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src,\"lxml\")\n",
    "\n",
    "    descrip = soup.find(\"div\", {\"class\":\"book-infos\"}).ul     \n",
    "    content = soup.find(\"div\", {\"id\":\"books-content\"}) \n",
    "    \n",
    "    \n",
    "    infos = list(soup.find(\"div\", class_='book-infos').stripped_strings)    # for other information about the book\n",
    "\n",
    "\n",
    "#     print(content)\n",
    "    \n",
    "    for info in infos:\n",
    "        if info == 'لغة الكتاب:':\n",
    "            book[\"language\"] = infos[infos.index(info) + 1]\n",
    "        if info == 'دار النشر:':\n",
    "            book[\"publishing house\"] = infos[infos.index(info) + 1]\n",
    "        if info == 'حجم الكتاب:':\n",
    "            book[\"size\"] = infos[infos.index(info) + 1]\n",
    "        if info == 'ملف الكتاب:':\n",
    "            book[\"format\"] = infos[infos.index(info) + 1]\n",
    "        if info == 'قسم الكتاب:':\n",
    "            book[\"category\"] = infos[infos.index(info) + 1][6:]\n",
    "\n",
    "\n",
    "    # Handle Empty Fields\n",
    "    if book[\"language\"] == \"عدد الصّفحات:\":\n",
    "        language.append(\" \")\n",
    "    else:\n",
    "        language.append(correct(book[\"language\"]))    # Correct\n",
    "\n",
    "\n",
    "    if book[\"publishing house\"] == \"حجم الكتاب:\":\n",
    "        publishing_house.append(\" \")\n",
    "    else:\n",
    "        publishing_house.append(correct(book[\"publishing house\"])) # Correct\n",
    "\n",
    "\n",
    "    size.append(book[\"size\"])\n",
    "\n",
    "\n",
    "    if book[\"format\"] == \"تبليغ حقوق الملكية:\":\n",
    "        format.append(\" \")\n",
    "    else:\n",
    "        format.append(book[\"format\"])\n",
    "\n",
    "\n",
    "    if book[\"category\"] == \"كتاب:\":\n",
    "        category.append(\" \")\n",
    "    else:\n",
    "        category.append(Correct(book[\"category\"])) # Correct\n",
    "\n",
    "\n",
    "#print(language)\n",
    "#print(publishing_house)\n",
    "#print(size)\n",
    "#print(format)\n",
    "#print(category)\n",
    "\n",
    "\n",
    "\n",
    "    paragraphs = content.find_all(['p', 'h4', 'h3' , 'h2' ,'li'])\n",
    "    res = \"\"\n",
    "    for pr in range(len(paragraphs)):\n",
    "        if(str(paragraphs[pr]).find(\"ملخص\") != -1 or str(paragraphs[pr]).find(\"تلخيص\") != -1):\n",
    "            pr += 1\n",
    "            if(pr < len(paragraphs) and str(paragraphs[pr]).find(\"تحميل رواية عربي\") != -1):\n",
    "                pr += 1\n",
    "            if(pr < len(paragraphs) and str(paragraphs[pr]).find(\"الروايات والكتب العربية تعتبر من الروابط بيننا\") != -1):\n",
    "                pr += 1\n",
    "            if(pr < len(paragraphs) and str(paragraphs[pr].find(\"تحميل كتب عربي\") != -1)):\n",
    "                pr += 1\n",
    "            while True:\n",
    "                if pr >= len(paragraphs) or str(paragraphs[pr]).find(\"نبذة عن كاتب\") != -1:\n",
    "                    break\n",
    "                res+= str(paragraphs[pr]) + \" \"\n",
    "                pr += 1\n",
    "    res = re.sub(r'[^(\\u0621-\\u064A\\u0660-\\u0669 | \\s)]', '',str(res))  # [^(\\u0621-\\u064A\\u0660-\\u0669 | \\s)] Remove Any Character Not Arabic\n",
    "    res = re.sub(r'\\s+', ' ',str(res))\n",
    "    res = Correct(res)   # Correct\n",
    "    \n",
    "    brief.append(res)\n",
    "#     print(res)\n",
    "#     print(\"---------------------------------------------------\")\n",
    "    \n",
    "\n",
    "\n",
    "    desc_text = \"\"\n",
    "    for li in descrip.find_all(\"li\"):\n",
    "        desc_text += li.text + \"/ \"\n",
    "    desc_text = desc_text[:-2]   # remove '/' from last text\n",
    "    numbers.append(re.findall(r'\\d{1,3}',desc_text))\n",
    "    \n",
    "#print(numbers)\n",
    "\n",
    "print(len(brief))\n",
    "\n",
    "for m in numbers:\n",
    "    if len(m) == 0:\n",
    "        m.append(1)\n",
    "        no_of_pages.append(m[0])\n",
    "    else :\n",
    "        no_of_pages.append(m[0])\n",
    "\n",
    "#print(no_of_pages)\n",
    "\n",
    "#print(len(no_of_pages))\n",
    "\n",
    "\n",
    "file_list = [Author , title , category ,  links , no_of_pages , language ,publishing_house ,size ,format, brief]\n",
    "imported = zip_longest(*file_list)\n",
    "\n",
    "with open('scrapping.csv',\"w\" , encoding = 'utf-8') as project :\n",
    "    wr = csv.writer(project)\n",
    "    wr.writerow([\"Author\", \"Title\", \"Category\", \"Link for PDF\", \"Number Of Pages\", \"Language\" , \"Publishing House\", \"Size\", \"Format\", \"Brief\"])\n",
    "    wr.writerows(imported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
